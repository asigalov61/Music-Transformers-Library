{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Performer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChcD8WZHlMG5"
      },
      "source": [
        "# Music Performer (v.1.0)\n",
        "\n",
        "### This is a work in progress so please check back for updates and improvements.\n",
        "\n",
        "***\n",
        "\n",
        "### Based on the code/repo of @lucidrains of GitHub:\n",
        "\n",
        "https://github.com/lucidrains/performer-pytorch\n",
        "\n",
        "***\n",
        "\n",
        "Project Los Angeles\n",
        "\n",
        "Tegridy Code 2021\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtYicUXydKpA"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhZrdm6udNdO"
      },
      "source": [
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "!pip install performer-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0jNRicNhQyv"
      },
      "source": [
        "%%writefile setup.sh\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbyYTQNVhZH7"
      },
      "source": [
        "!sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d8q3nCutsJK"
      },
      "source": [
        "%cd /content/tegridy-tools/tegridy-tools\n",
        "import TMIDI\n",
        "%cd /content/\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "from performer_pytorch import PerformerLM\n",
        "from performer_pytorch.autoregressive_wrapper import AutoregressiveWrapper\n",
        "from apex import amp\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlP9fO7Kg744"
      },
      "source": [
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(1e5)\n",
        "BATCH_SIZE = 12\n",
        "GRADIENT_ACCUMULATE_EVERY = 4\n",
        "LEARNING_RATE = 3e-4\n",
        "VALIDATE_EVERY  = 100\n",
        "GENERATE_EVERY  = 500\n",
        "GENERATE_LENGTH = 2048\n",
        "SEQ_LEN = 4096\n",
        "\n",
        "# helpers\n",
        "\n",
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "def decode_token(token):\n",
        "    return str(chr(max(32, token)))\n",
        "\n",
        "def decode_tokens(tokens):\n",
        "    return ''.join(list(map(decode_token, tokens)))\n",
        "\n",
        "# instantiate model\n",
        "\n",
        "model = PerformerLM(\n",
        "    num_tokens = 256,\n",
        "    dim = 512,\n",
        "    depth = 6,\n",
        "    max_seq_len = SEQ_LEN,\n",
        "    heads = 8,\n",
        "    causal = True,\n",
        "    reversible = True,\n",
        "    nb_features = 256,\n",
        "    use_scalenorm = True,\n",
        "    local_attn_heads = (8, 8, 8, 6, 4, 2)\n",
        ")\n",
        "\n",
        "model = AutoregressiveWrapper(model)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHT07SF3dHCM"
      },
      "source": [
        "# prepare enwik8 data\n",
        "\n",
        "with open('/content/Music-Reformer_INT_Dataset.txt') as file:\n",
        "    X = file.read()\n",
        "    Y = []\n",
        "    for x in X.split('\\n'):\n",
        "      Y.append(int(x))\n",
        "    trX, vaX = np.split(Y, [int(1000000)])\n",
        "    data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
        "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))\n",
        "\n",
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scaler = GradScaler()\n",
        "\n",
        "# training\n",
        "\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
        "        with autocast():\n",
        "            loss = model(next(train_loader), return_loss = True)\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "    print(f'training loss: {loss.item()}')\n",
        "\n",
        "    scaler.unscale_(optim)\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    scaler.step(optim)\n",
        "    scaler.update()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    if i % VALIDATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss = model(next(val_loader), return_loss = True)\n",
        "            print(f'validation loss: {loss.item()}')\n",
        "\n",
        "    if i % GENERATE_EVERY == 0 and i != 0:\n",
        "        model.eval()\n",
        "        inp = random.choice(val_dataset)[:-1]\n",
        "        prime = decode_tokens(inp)\n",
        "        print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "        sample = model.generate(inp, GENERATE_LENGTH)\n",
        "        output_str = decode_tokens(sample)\n",
        "        print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbIB5fQJsSFz"
      },
      "source": [
        "model.eval()\n",
        "inp = random.choice(val_dataset)[:-1]\n",
        "prime = decode_tokens(inp)\n",
        "print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "sample = model.generate(inp, GENERATE_LENGTH, temperature=0.7)\n",
        "output_str = decode_tokens(sample)\n",
        "print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "rw5lCFAas-w9"
      },
      "source": [
        "#@title Convert generated output to MIDI.\n",
        "# Run the cells below to convert generated output to MIDI.\n",
        "# If you getting errors/halts, regenerate the output again.\n",
        "# Model must be sufficiently trained. Rec. 0.90+ accuracy for the output to make sense and pass error control.\n",
        "\n",
        "#TXT = TMIDI.Tegridy_INT_String_to_TXT_Converter(input, line_by_line_input=False)\n",
        "SONG = TMIDI.Tegridy_Optimus_TXT_to_Notes_Converter(output_str, has_MIDI_channels=False, char_encoding_offset=33, simulate_velocity=False, dataset_MIDI_events_time_denominator=10, line_by_line_dataset=False, has_velocities=True)\n",
        "stats = TMIDI.Tegridy_SONG_to_MIDI_Converter(SONG[0], output_file_name='/content/Music-Reformer_MIDI')\n",
        "print(stats)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}