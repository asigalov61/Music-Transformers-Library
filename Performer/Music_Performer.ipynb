{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Performer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChcD8WZHlMG5"
      },
      "source": [
        "# Music Performer (v.1.0)\n",
        "\n",
        "### This is a work in progress so please check back for updates and improvements.\n",
        "\n",
        "***\n",
        "\n",
        "### Based on the code/repo of @lucidrains of GitHub:\n",
        "\n",
        "https://github.com/lucidrains/performer-pytorch\n",
        "\n",
        "***\n",
        "\n",
        "Project Los Angeles\n",
        "\n",
        "Tegridy Code 2021\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtYicUXydKpA"
      },
      "source": [
        "# Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhZrdm6udNdO",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "!pip install performer-pytorch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0jNRicNhQyv",
        "cellView": "form"
      },
      "source": [
        "#@title Create NVIDIA apex setup file\n",
        "%%writefile setup.sh\n",
        "\n",
        "git clone https://github.com/NVIDIA/apex\n",
        "pip install -v --no-cache-dir --global-option=\"--cpp_ext\" ./apex"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbyYTQNVhZH7",
        "cellView": "form"
      },
      "source": [
        "#@title Run NVIDIA apex setup\n",
        "!sh setup.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d8q3nCutsJK",
        "cellView": "form"
      },
      "source": [
        "#@title Import needed modules\n",
        "%cd /content/tegridy-tools/tegridy-tools\n",
        "import TMIDI\n",
        "%cd /content/\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "from performer_pytorch import PerformerLM\n",
        "from performer_pytorch.autoregressive_wrapper import AutoregressiveWrapper\n",
        "from apex import amp\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.cuda.amp import autocast, GradScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlTjX8mBhcQj"
      },
      "source": [
        "# Prep MIDIs and TXT/INT datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "v_501j14h33v"
      },
      "source": [
        "#@title Download special Tegridy Piano MIDI dataset\n",
        "\n",
        "#@markdown Works best stand-alone/as-is for the optimal results\n",
        "%cd /content/Dataset/\n",
        "\n",
        "!wget 'https://github.com/asigalov61/Tegridy-MIDI-Dataset/raw/master/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "!unzip -j '/content/Dataset/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "!rm '/content/Dataset/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "aj47ZcfRhh9w"
      },
      "source": [
        "#@title Process MIDIs to special MIDI dataset with Tegridy MIDI Processor\n",
        "#@markdown NOTES:\n",
        "\n",
        "#@markdown 1) Dataset MIDI file names are used as song names. Feel free to change it to anything you like.\n",
        "\n",
        "#@markdown 2) Best results are achieved with the single-track, single-channel, single-instrument MIDI 0 files with plain English names (avoid special or sys/foreign chars)\n",
        "\n",
        "#@markdown 3) MIDI Channel = -1 means all MIDI channels except drums. MIDI Channel = 16 means all channels will be processed. Otherwise, only single indicated MIDI channel will be processed.\n",
        "\n",
        "file_name_to_output_dataset_to = \"/content/Music-Performer_TXT_Dataset\" #@param {type:\"string\"}\n",
        "desired_MIDI_channel_to_process = 16 #@param {type:\"slider\", min:-1, max:16, step:1}\n",
        "encode_velocities = True #@param {type:\"boolean\"}\n",
        "encode_MIDI_channels = False #@param {type:\"boolean\"}\n",
        "add_transposed_dataset_by_this_many_pitches = 0 #@param {type:\"slider\", min:-12, max:12, step:1}\n",
        "chordify_input_MIDIs = False #@param {type:\"boolean\"}\n",
        "time_denominator = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "chars_encoding_offset = 33 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "print('Starting up...')\n",
        "###########\n",
        "\n",
        "average_note_pitch = 0\n",
        "min_note = 127\n",
        "max_note = 0\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "ev = 0\n",
        "\n",
        "chords_list_f = []\n",
        "melody_list_f = []\n",
        "\n",
        "chords_list = []\n",
        "chords_count = 0\n",
        "\n",
        "melody_chords = []\n",
        "melody_count = 0\n",
        "\n",
        "TXT_String = 'DATASET=Music-Performer-Dataset' + chr(10)\n",
        "\n",
        "TXT = ''\n",
        "melody = []\n",
        "chords = []\n",
        "\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/Dataset/\"\n",
        "os.chdir(dataset_addr)\n",
        "filez = os.listdir(dataset_addr)\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm.auto.tqdm(filez):\n",
        "  try:\n",
        "    fn = os.path.basename(f)\n",
        "    fn1 = fn.split('.')[0]\n",
        "    #notes = song_notes_list[song_notes_list.index(fn1)+1]\n",
        "\n",
        "\n",
        "    files_count += 1\n",
        "    TXT, melody, chords = TMIDI.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=encode_MIDI_channels, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_channel=desired_MIDI_channel_to_process, MIDI_patch=range(0, 127))\n",
        "    TXT_String += TXT\n",
        "    melody_list_f += melody\n",
        "    chords_list_f += chords\n",
        "\n",
        "    if add_transposed_dataset_by_this_many_pitches != 0:\n",
        "\n",
        "      TXT, melody, chords = TMIDI.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=encode_MIDI_channels, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_channel=desired_MIDI_channel_to_process, transpose_by=add_transposed_dataset_by_this_many_pitches, MIDI_patch=range(0, 127))\n",
        "      TXT_String += TXT\n",
        "      melody_list_f += melody\n",
        "      chords_list_f += chords       \n",
        "  \n",
        "  except:\n",
        "    print('Problematic MIDI:', f)\n",
        "    continue\n",
        "\n",
        "print('Task complete :)')\n",
        "print('==================================================')\n",
        "print('Number of processed dataset MIDI files:', files_count)\n",
        "print('Number of MIDI chords recorded:', len(chords_list_f))\n",
        "print('First chord event:', chords_list_f[0], 'Last chord event:', chords_list_f[-1]) \n",
        "print('Number of recorded melody events:', len(melody_list_f))\n",
        "print('First melody event:', melody_list_f[0], 'Last Melody event:', melody_list_f[-1])\n",
        "print('Total number of MIDI events recorded:', len(chords_list_f) + len(melody_list_f))\n",
        "\n",
        "# Writing dataset to TXT file\n",
        "with open(file_name_to_output_dataset_to + '.txt', 'wb') as f:\n",
        "  f.write(TXT_String.encode('utf-8', 'replace'))\n",
        "  f.close\n",
        "\n",
        "# Dataset\n",
        "MusicDataset = [chords_list_f, melody_list_f]\n",
        "\n",
        "# Writing dataset to pickle file\n",
        "TMIDI.Tegridy_Pickle_File_Writer(MusicDataset, file_name_to_output_dataset_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "W0iR8eSch582"
      },
      "source": [
        "#@title Process the TXT MIDI dataset to TXT INT dataset\n",
        "full_path_to_TXT_dataset = \"/content/Music-Performer_TXT_Dataset.txt\" #@param {type:\"string\"}\n",
        "\n",
        "print('Processing...')\n",
        "with open(full_path_to_TXT_dataset) as file:\n",
        "  z = file.read()\n",
        "  file.close()\n",
        "  Y = list(z)\n",
        "\n",
        "string = '\\n'.join([str(ord(item)) for item in Y if ord(item) < 256])\n",
        "\n",
        "with open('/content/Music-Performer_INT_Dataset.txt', 'w') as file:\n",
        "  file.write(string)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "FcgsJeSVh-5D"
      },
      "source": [
        "#@title Load INT dataset into memory and setup the dataset\n",
        "full_path_to_INT_dataset = \"/content/Music-Performer_INT_Dataset.txt\" #@param {type:\"string\"}\n",
        "dataset_split_ratio = 0.9 #@param {type:\"slider\", min:0.1, max:0.9, step:0.1}\n",
        "\n",
        "print('Processing...')\n",
        "with open(full_path_to_INT_dataset) as file:\n",
        "    X = file.read()\n",
        "    H = []\n",
        "    for x in X.split('\\n'):\n",
        "      H.append(int(x))\n",
        "\n",
        "trX, vaX = np.split(H, [int(len(H) * dataset_split_ratio)])\n",
        "data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHYdxwGChEv-"
      },
      "source": [
        "# Setup and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlP9fO7Kg744",
        "cellView": "form"
      },
      "source": [
        "#@title Instantiate the model and the helper functions\n",
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(1e5)\n",
        "BATCH_SIZE = 12\n",
        "GRADIENT_ACCUMULATE_EVERY = 4\n",
        "LEARNING_RATE = 3e-4\n",
        "VALIDATE_EVERY  = 100\n",
        "GENERATE_EVERY  = 500\n",
        "GENERATE_LENGTH = 2048\n",
        "SEQ_LEN = 4096\n",
        "\n",
        "# helpers\n",
        "\n",
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "def decode_token(token):\n",
        "    return str(chr(max(32, token)))\n",
        "\n",
        "def decode_tokens(tokens):\n",
        "    return ''.join(list(map(decode_token, tokens)))\n",
        "\n",
        "# instantiate model\n",
        "\n",
        "model = PerformerLM(\n",
        "    num_tokens = 256,\n",
        "    dim = 512,\n",
        "    depth = 6,\n",
        "    max_seq_len = SEQ_LEN,\n",
        "    heads = 8,\n",
        "    causal = True,\n",
        "    reversible = True,\n",
        "    nb_features = 256,\n",
        "    use_scalenorm = True,\n",
        "    local_attn_heads = (8, 8, 8, 6, 4, 2)\n",
        ")\n",
        "\n",
        "model = AutoregressiveWrapper(model)\n",
        "model.cuda()\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
        "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))\n",
        "\n",
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scaler = GradScaler()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "df9HzYaeJIJA",
        "cellView": "form"
      },
      "source": [
        "#@title Train the model\n",
        "# training\n",
        "\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
        "        with autocast():\n",
        "            loss = model(next(train_loader), return_loss = True)\n",
        "        scaler.scale(loss).backward()\n",
        "\n",
        "    print(f'training loss: {loss.item()}')\n",
        "\n",
        "    scaler.unscale_(optim)\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    scaler.step(optim)\n",
        "    scaler.update()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    if i % VALIDATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss = model(next(val_loader), return_loss = True)\n",
        "            print(f'validation loss: {loss.item()}')\n",
        "\n",
        "    if i % GENERATE_EVERY == 0 and i != 0:\n",
        "        model.eval()\n",
        "        inp = random.choice(val_dataset)[:-1]\n",
        "        prime = decode_tokens(inp)\n",
        "        print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "        sample = model.generate(inp, GENERATE_LENGTH)\n",
        "        output_str = decode_tokens(sample)\n",
        "        print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZdlABzvhB2n"
      },
      "source": [
        "# Save and Load/Reload the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ln3LD6p7b78j",
        "cellView": "form"
      },
      "source": [
        "#@title Save the model\n",
        "torch.save(model.state_dict(), '/content/Music-Performer-Model.pth')\n",
        "\n",
        "checkpoint = {'state_dict': model.state_dict(),'optimizer' :optim.state_dict()}\n",
        "torch.save(checkpoint, '/content/Music-Performer-Model_sd_opt.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Et7BPNL0gOLX"
      },
      "source": [
        "#@title Load/Reload the model\n",
        "torch.load('/content/Music-Performer-Model_sd_opt.pth')\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBQuv-MHgiSs"
      },
      "source": [
        "# Generate from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbIB5fQJsSFz",
        "cellView": "form"
      },
      "source": [
        "#@title Generate Music\n",
        "model_temperature = 0.8 #@param {type:\"slider\", min:0.1, max:2, step:0.1}\n",
        "number_of_tokens_to_generate = 1032 #@param {type:\"slider\", min:8, max:8192, step:128}\n",
        "\n",
        "model.eval()\n",
        "inp = random.choice(val_dataset)[:-1]\n",
        "prime = decode_tokens(inp)\n",
        "print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "sample = model.generate(inp, number_of_tokens_to_generate, temperature=model_temperature)\n",
        "output_str = decode_tokens(sample)\n",
        "print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw5lCFAas-w9",
        "cellView": "form"
      },
      "source": [
        "#@title Convert generated output to MIDI\n",
        "time_denominator = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "encoding_has_velocities = True #@param {type:\"boolean\"}\n",
        "simulate_velocity = False #@param {type:\"boolean\"}\n",
        "char_encoding_offset = 33 #@param {type:\"number\"}\n",
        "\n",
        "SONG = TMIDI.Tegridy_Optimus_TXT_to_Notes_Converter('SONG=SONG ' + output_str, line_by_line_dataset = False, has_MIDI_channels=False, has_velocities=encoding_has_velocities, dataset_MIDI_events_time_denominator=time_denominator, char_encoding_offset=char_encoding_offset, simulate_velocity=simulate_velocity)\n",
        "stats = TMIDI.Tegridy_SONG_to_MIDI_Converter(SONG[0], output_file_name='/content/Music-Performer_MIDI', output_signature='Music Performer')\n",
        "print(stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf8XaklEg_G0"
      },
      "source": [
        "# Congrats! You did it :)"
      ]
    }
  ]
}