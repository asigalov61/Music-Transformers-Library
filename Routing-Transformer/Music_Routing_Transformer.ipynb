{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_Routing_Transformer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BcapmOrlmWl"
      },
      "source": [
        "# Music Routing Transformer (v.1.0)\n",
        "\n",
        "### This is a work in progress so please check back for updates and improvements.\n",
        "\n",
        "***\n",
        "\n",
        "### Based on the code/repo of @lucidrains of GitHub:\n",
        "\n",
        "https://github.com/lucidrains/routing-transformer\n",
        "\n",
        "***\n",
        "\n",
        "Project Los Angeles\n",
        "\n",
        "Tegridy Code 2021\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "_yWSXHt_d-58"
      },
      "source": [
        "#@title Install dependencies\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "!pip install routing_transformer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "faBnZvGrqtBs"
      },
      "source": [
        "#@title Import needed modules\n",
        "%cd /content/tegridy-tools/tegridy-tools\n",
        "import TMIDI\n",
        "%cd /content/\n",
        "\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "from routing_transformer import RoutingTransformerLM\n",
        "from routing_transformer.autoregressive_wrapper import AutoregressiveWrapper\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(1e5)\n",
        "BATCH_SIZE = 8\n",
        "GRADIENT_ACCUMULATE_EVERY = 4\n",
        "LEARNING_RATE = 3e-4\n",
        "VALIDATE_EVERY  = 100\n",
        "GENERATE_EVERY  = 500\n",
        "GENERATE_LENGTH = 512\n",
        "SEQ_LEN = 4096"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "mjpdgoIfqggW"
      },
      "source": [
        "#@title Download special Tegridy Piano MIDI dataset\n",
        "\n",
        "#@markdown Works best stand-alone/as-is for the optimal results\n",
        "%cd /content/Dataset/\n",
        "\n",
        "!wget 'https://github.com/asigalov61/Tegridy-MIDI-Dataset/raw/master/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "!unzip -j '/content/Dataset/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "!rm '/content/Dataset/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-ThPwCyyqehS"
      },
      "source": [
        "#@title Process MIDIs to special MIDI dataset with Tegridy MIDI Processor\n",
        "#@markdown NOTES:\n",
        "\n",
        "#@markdown 1) Dataset MIDI file names are used as song names. Feel free to change it to anything you like.\n",
        "\n",
        "#@markdown 2) Best results are achieved with the single-track, single-channel, single-instrument MIDI 0 files with plain English names (avoid special or sys/foreign chars)\n",
        "\n",
        "#@markdown 3) MIDI Channel = -1 means all MIDI channels. MIDI Channel = 16 means all channels will be processed. Otherwise, only single indicated MIDI channel will be processed.\n",
        "\n",
        "file_name_to_output_dataset_to = \"/content/Music-Routing-Transformer_TXT_Dataset\" #@param {type:\"string\"}\n",
        "desired_MIDI_channel_to_process = -1 #@param {type:\"slider\", min:-1, max:15, step:1}\n",
        "encode_velocities = True #@param {type:\"boolean\"}\n",
        "chordify_input_MIDIs = False #@param {type:\"boolean\"}\n",
        "time_denominator = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "chars_encoding_offset = 33 #@param {type:\"number\"}\n",
        "\n",
        "print('TMIDI Processor')\n",
        "print('Starting up...')\n",
        "\n",
        "###########\n",
        "\n",
        "average_note_pitch = 0\n",
        "min_note = 127\n",
        "max_note = 0\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "ev = 0\n",
        "\n",
        "chords_list_f = []\n",
        "melody_list_f = []\n",
        "\n",
        "chords_list = []\n",
        "chords_count = 0\n",
        "\n",
        "melody_chords = []\n",
        "melody_count = 0\n",
        "\n",
        "TXT_String = 'DATASET=Routing-Transformer-Music-Dataset' + chr(10)\n",
        "\n",
        "TXT = ''\n",
        "melody = []\n",
        "chords = []\n",
        "\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/Dataset/\"\n",
        "os.chdir(dataset_addr)\n",
        "filez = os.listdir(dataset_addr)\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm.auto.tqdm(filez):\n",
        "  try:\n",
        "\n",
        "    files_count += 1\n",
        "    TXT, melody, chords = TMIDI.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=False, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_patch=range(0,127))\n",
        "    melody_list_f += melody\n",
        "    chords_list_f += chords\n",
        "    TXT_String += TXT\n",
        "    \n",
        "  \n",
        "  except:\n",
        "    print('Bad MIDI:', f)\n",
        "    continue\n",
        "\n",
        "print('Task complete :)')\n",
        "print('==================================================')\n",
        "print('Number of processed dataset MIDI files:', files_count)\n",
        "print('Number of MIDI chords recorded:', len(chords_list_f))\n",
        "print('First chord event:', chords_list_f[0], 'Last chord event:', chords_list_f[-1]) \n",
        "print('Number of recorded melody events:', len(melody_list_f))\n",
        "print('First melody event:', melody_list_f[0], 'Last Melody event:', melody_list_f[-1])\n",
        "print('Total number of MIDI events recorded:', len(chords_list_f) + len(melody_list_f))\n",
        "\n",
        "# Writing dataset to TXT file\n",
        "with open(file_name_to_output_dataset_to + '.txt', 'wb') as f:\n",
        "  f.write(TXT_String.encode('utf-8', 'replace'))\n",
        "  f.close\n",
        "\n",
        "# Dataset\n",
        "MusicDataset = [chords_list_f, melody_list_f]\n",
        "\n",
        "# Writing dataset to pickle file\n",
        "TMIDI.Tegridy_Pickle_File_Writer(MusicDataset, file_name_to_output_dataset_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "kf2ZEcy0qoKT"
      },
      "source": [
        "#@title Process the TXT MIDI dataset to TXT INT dataset\n",
        "full_path_to_TXT_dataset = \"/content/Music-Routing-Transformer_TXT_Dataset.txt\" #@param {type:\"string\"}\n",
        "with open(full_path_to_TXT_dataset, 'r') as file:\n",
        "  z = file.read()\n",
        "  file.close()\n",
        "  Z = z.encode('utf8')\n",
        "  Y = list(Z)\n",
        "\n",
        "string = '\\n'.join([str(item) for item in Y if item < 256])\n",
        "\n",
        "with open('/content/Music-Routing-Transformer_INT_Dataset.txt', 'w') as file:\n",
        "  file.write(string)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "LKVpRLGvecJJ"
      },
      "source": [
        "#@title Load INT dataset into memory and setup dataset\n",
        "full_path_to_INT_dataset = \"/content/Music-Routing-Transformer_INT_Dataset.txt\" #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "with open(full_path_to_INT_dataset) as file:\n",
        "    X = file.read()\n",
        "    Y = []\n",
        "    for x in X.split('\\n'):\n",
        "      Y.append(int(x))\n",
        "    trX, vaX = np.split(Y, [int(1000000)])\n",
        "    data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "TZXbAgFReQcP"
      },
      "source": [
        "#@title Instantiate the model\n",
        "# helpers\n",
        "\n",
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "def decode_token(token):\n",
        "    return str(chr(max(32, token)))\n",
        "\n",
        "def decode_tokens(tokens):\n",
        "    return ''.join(list(map(decode_token, tokens)))\n",
        "\n",
        "# instantiate model\n",
        "\n",
        "model = RoutingTransformerLM(\n",
        "    num_tokens = 256,\n",
        "    dim = 512,\n",
        "    depth = 6,\n",
        "    max_seq_len = SEQ_LEN,\n",
        "    heads = 8,\n",
        "    causal = True,\n",
        "    window_size = 128,\n",
        "    n_local_attn_heads = (8, 8, 8, 4, 4, 4)\n",
        ")\n",
        "\n",
        "model = AutoregressiveWrapper(model)\n",
        "model.cuda()\n",
        "\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
        "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))\n",
        "\n",
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "267fqtmheeDw"
      },
      "source": [
        "#@title Train the model\n",
        "# training\n",
        "\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
        "        loss = model(next(train_loader), return_loss = True)\n",
        "        loss.backward()\n",
        "\n",
        "    print(f'training loss: {loss.item()}')\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    if i % VALIDATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss = model(next(val_loader), return_loss = True)\n",
        "            print(f'validation loss: {loss.item()}')\n",
        "\n",
        "    if i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        inp = random.choice(val_dataset)[:-1]\n",
        "        prime = decode_tokens(inp)\n",
        "        print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "        sample = model.generate(inp, GENERATE_LENGTH)\n",
        "        output_str = decode_tokens(sample)\n",
        "        print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "-Xgd0ZB0xXGK"
      },
      "source": [
        "#@title Save the model\n",
        "torch.save(model.state_dict(), '/content/model.pth')\n",
        "\n",
        "checkpoint = {'state_dict': model.state_dict(),'optimizer' :optim.state_dict()}\n",
        "torch.save(checkpoint, '/content/model_sd_opt.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "owbOK4jHIzZr"
      },
      "source": [
        "#@title Load the model\n",
        "torch.load('/content/model_sd_opt.pth')\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "isOdHHoNuoEl"
      },
      "source": [
        "#@title Generate Music\n",
        "model_temperature = 0.8 #@param {type:\"slider\", min:0.1, max:2, step:0.1}\n",
        "number_of_tokens_to_generate = 2056 #@param {type:\"slider\", min:8, max:8192, step:128}\n",
        "\n",
        "model.eval()\n",
        "inp = random.choice(val_dataset)[:-1]\n",
        "prime = decode_tokens(inp)\n",
        "print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "sample = model.generate(inp, number_of_tokens_to_generate, temperature=model_temperature)\n",
        "output_str = decode_tokens(sample)\n",
        "print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "bPlgvYdSsjtJ"
      },
      "source": [
        "#@title Convert generated output to MIDI.\n",
        "# Run the cells below to convert generated output to MIDI.\n",
        "# If you getting errors/halts, regenerate the output again.\n",
        "# Model must be sufficiently trained. Rec. 0.90+ accuracy for the output to make sense and pass error control.\n",
        "\n",
        "#TXT = TMIDI.Tegridy_INT_String_to_TXT_Converter(input, line_by_line_input=False)\n",
        "SONG = TMIDI.Tegridy_Optimus_TXT_to_Notes_Converter('SONG=TEST' + output_str, has_MIDI_channels=False, char_encoding_offset=33, simulate_velocity=False, dataset_MIDI_events_time_denominator=10, line_by_line_dataset=False, has_velocities=True)\n",
        "stats = TMIDI.Tegridy_SONG_to_MIDI_Converter(SONG[0], output_file_name='/content/Music-Reformer_MIDI')\n",
        "print(stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dMhHu9rtaVR"
      },
      "source": [
        "# Congrats! You did it :)"
      ]
    }
  ]
}