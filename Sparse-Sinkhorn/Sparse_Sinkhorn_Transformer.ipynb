{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sparse_Sinkhorn_Transformer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FB4Ah59hAM-Z"
      },
      "source": [
        "# Sparse Sinkhorn Transformer (PyTorch/GPU) (Ver 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "### Credit for the PyTorch Reformer implementation goes out to @lucidrains of GitHub:\n",
        "\n",
        "https://github.com/lucidrains/sinkhorn-transformer\n",
        "\n",
        "***\n",
        "\n",
        "This is a work in progress so please check back for updates.\n",
        "\n",
        "***\n",
        "\n",
        "Project Los Angeles\n",
        "\n",
        "Tegridy Code 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XCcbVyR8BUeX"
      },
      "source": [
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "!pip install sinkhorn_transformer\n",
        "!pip install local-attention"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Ty1x1r1BZ7j"
      },
      "source": [
        "%cd /content/tegridy-tools/tegridy-tools/\n",
        "import TMIDI\n",
        "%cd /content/\n",
        "\n",
        "from sinkhorn_transformer import SinkhornTransformerLM\n",
        "from sinkhorn_transformer.autoregressive_wrapper import AutoregressiveWrapper\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(1e5)\n",
        "BATCH_SIZE = 28\n",
        "GRADIENT_ACCUMULATE_EVERY = 4\n",
        "LEARNING_RATE = 1e-4\n",
        "VALIDATE_EVERY  = 100\n",
        "GENERATE_EVERY  = 500\n",
        "GENERATE_LENGTH = 512\n",
        "SEQ_LEN = 4096\n",
        "\n",
        "# helpers\n",
        "\n",
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "def decode_token(token):\n",
        "    return str(chr(max(32, token)))\n",
        "\n",
        "def decode_tokens(tokens):\n",
        "    return ''.join(list(map(decode_token, tokens)))\n",
        "\n",
        "# instantiate model\n",
        "\n",
        "model = SinkhornTransformerLM(\n",
        "    num_tokens = 256,\n",
        "    emb_dim = 128,\n",
        "    dim = 512,\n",
        "    depth = 8,\n",
        "    max_seq_len = SEQ_LEN,\n",
        "    heads = 8,\n",
        "    bucket_size = 128,\n",
        "    ff_chunks = 2,\n",
        "    causal = True,\n",
        "    reversible = True,\n",
        "    attn_dropout = 0.1,\n",
        "    n_local_attn_heads = 4\n",
        ")\n",
        "\n",
        "model = AutoregressiveWrapper(model)\n",
        "model.cuda()\n",
        "\n",
        "# prepare enwik8 data\n",
        "\n",
        "#@title Process the TXT MIDI dataset to TXT INT MIDI dataset\n",
        "\n",
        "with open('/content/Optimus-VIRTUOSO-Music-Dataset.txt', 'r') as file:\n",
        "  z = file.read()\n",
        "  Z = z.encode('utf8')\n",
        "  Y = list(Z)\n",
        "\n",
        "trX, vaX = np.split(Y, [1000000])\n",
        "data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
        "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))\n",
        "\n",
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-COc5UCCEsm"
      },
      "source": [
        "# training\n",
        "\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
        "        loss = model(next(train_loader), return_loss = True)\n",
        "        loss.backward()\n",
        "\n",
        "    print(f'training loss: {loss.item()}')\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    if i % VALIDATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss = model(next(val_loader), return_loss = True)\n",
        "            print(f'validation loss: {loss.item()}')\n",
        "\n",
        "    if i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        inp = random.choice(val_dataset)[:-1]\n",
        "        prime = decode_tokens(inp)\n",
        "        print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "        sample = model.generate(inp, GENERATE_LENGTH)\n",
        "        output_str = decode_tokens(sample)\n",
        "        print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIcEn0wXWrpL"
      },
      "source": [
        "torch.save(model.state_dict, '/content/model_sd.pth')\n",
        "torch.save(model, '/content/model.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJdsOb7JV1ut"
      },
      "source": [
        "model.eval()\n",
        "inp = random.choice(val_dataset)[:-1]\n",
        "prime = decode_tokens(inp)\n",
        "print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "sample = model.generate(inp, 2048)\n",
        "output_str = decode_tokens(sample)\n",
        "print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAydq9MLX3AF"
      },
      "source": [
        "S = TMIDI.Tegridy_Optimus_TXT_to_Notes_Converter('SONG=TEST' + output_str, line_by_line_dataset=False, has_velocities=True, has_MIDI_channels=False, dataset_MIDI_events_time_denominator=10, char_encoding_offset=0, save_only_first_composition=True, simulate_velocity=False)\n",
        "stats = TMIDI.Tegridy_SONG_to_MIDI_Converter(SONG=S[0], output_file_name='/content/test')\n",
        "print(stats)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}