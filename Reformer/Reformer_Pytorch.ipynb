{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reformer-Pytorch.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5mjL1xn7LHj"
      },
      "source": [
        "# Music Reformer (PyTorch/GPU) (Ver 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Credit for the PyTorch Reformer implementation goes out to @lucidrains of GitHub: \n",
        "\n",
        "https://github.com/lucidrains/reformer-pytorch\n",
        "\n",
        "***\n",
        "\n",
        "This is a work in progress so please check back for updates.\n",
        "\n",
        "***\n",
        "\n",
        "Project Los Angeles\n",
        "\n",
        "Tegridy Code 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn8HXMbFEXnD"
      },
      "source": [
        "!pip install reformer_pytorch\n",
        "!git clone https://github.com/asigalov61/tegridy-tools"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gj3uWZ8JEOdE"
      },
      "source": [
        "%cd /content/tegridy-tools/tegridy-tools/\n",
        "import TMIDI\n",
        "%cd /content/\n",
        "\n",
        "from reformer_pytorch import ReformerLM\n",
        "from reformer_pytorch.generative_tools import TrainingWrapper\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(1e5)\n",
        "BATCH_SIZE = 20\n",
        "GRADIENT_ACCUMULATE_EVERY = 4\n",
        "LEARNING_RATE = 1e-4\n",
        "VALIDATE_EVERY  = 100\n",
        "GENERATE_EVERY  = 500\n",
        "GENERATE_LENGTH = 1024\n",
        "SEQ_LEN = 4096\n",
        "\n",
        "# helpers\n",
        "\n",
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "def decode_token(token):\n",
        "    return str(chr(max(32, token)))\n",
        "\n",
        "def decode_tokens(tokens):\n",
        "    return ''.join(list(map(decode_token, tokens)))\n",
        "\n",
        "# instantiate model\n",
        "\n",
        "model = ReformerLM(\n",
        "    dim = 512,\n",
        "    depth = 6,\n",
        "    max_seq_len = SEQ_LEN,\n",
        "    num_tokens = 256,\n",
        "    heads = 8,\n",
        "    bucket_size = 64,\n",
        "    n_hashes = 4,\n",
        "    ff_chunks = 10,\n",
        "    lsh_dropout = 0.1,\n",
        "    weight_tie = True,\n",
        "    causal = True,\n",
        "    n_local_attn_heads = 4,\n",
        "    use_full_attn = False # set this to true for comparison with full attention\n",
        ")\n",
        "\n",
        "model = TrainingWrapper(model)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xr7FY0RjEgdT"
      },
      "source": [
        "#@title Process the TXT MIDI dataset to TXT INT MIDI dataset\n",
        "full_path_to_TXT_dataset = \"/content/Music-Reformer_TXT_Dataset.txt\" #@param {type:\"string\"}\n",
        "with open(full_path_to_TXT_dataset, 'r') as file:\n",
        "  z = file.read()\n",
        "Z = z.encode('utf8')\n",
        "Y = list(Z)\n",
        "\n",
        "# prepare enwik8 data\n",
        "\n",
        "trX, vaX = np.split(Y, [1000000])\n",
        "data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
        "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))\n",
        "\n",
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11JVvVB1EgOA"
      },
      "source": [
        "# training\n",
        "\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
        "        loss = model(next(train_loader), return_loss = True)\n",
        "        loss.backward()\n",
        "\n",
        "    print(f'training loss: {loss.item()}')\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    if i % VALIDATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss = model(next(val_loader), return_loss = True)\n",
        "            print(f'validation loss: {loss.item()}')\n",
        "\n",
        "    if i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        inp = random.choice(val_dataset)[:-1]\n",
        "        prime = decode_tokens(inp)\n",
        "        print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "        sample = model.generate(inp, GENERATE_LENGTH)\n",
        "        output_str = decode_tokens(sample)\n",
        "        print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tQ8Wj_MyhA4X"
      },
      "source": [
        "model.eval()\n",
        "inp = random.choice(val_dataset)[:-1]\n",
        "prime = decode_tokens(inp)\n",
        "print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "sample = model.generate(inp, GENERATE_LENGTH)\n",
        "output_str = decode_tokens(sample)\n",
        "print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxmGDEdzlfXr"
      },
      "source": [
        "S = TMIDI.Tegridy_Optimus_TXT_to_Notes_Converter('SONG=TEST' + output_str, line_by_line_dataset=False, has_velocities=True, has_MIDI_channels=False, dataset_MIDI_events_time_denominator=10, char_encoding_offset=33, save_only_first_composition=True, simulate_velocity=False)\n",
        "stats = TMIDI.Tegridy_SONG_to_MIDI_Converter(SONG=S[0], output_file_name='/content/test')\n",
        "print(stats)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}