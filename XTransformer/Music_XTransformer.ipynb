{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_XTransformer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8p4NIXjC6vs"
      },
      "source": [
        "# Music XTransformer (PyTorch/GPU) (Ver 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Credit for the PyTorch Reformer implementation goes out to @lucidrains of GitHub: \n",
        "\n",
        "https://github.com/lucidrains/x-transformers\n",
        "\n",
        "***\n",
        "\n",
        "This is a work in progress so please check back for updates.\n",
        "\n",
        "***\n",
        "\n",
        "Project Los Angeles\n",
        "\n",
        "Tegridy Code 2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2IUeSaiveLL",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "!pip install x-transformers\n",
        "!pip install numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "LTR81Sflrb7_"
      },
      "source": [
        "#@title Import modules\n",
        "import numpy as np\n",
        "import os\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "import TMIDI\n",
        "os.chdir('/content/')\n",
        "\n",
        "from x_transformers import TransformerWrapper, Decoder\n",
        "from x_transformers.autoregressive_wrapper import AutoregressiveWrapper\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7czqOs-OeVO",
        "cellView": "form"
      },
      "source": [
        "#@title Setup and intialize the model\n",
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(1e5)\n",
        "BATCH_SIZE = 6\n",
        "GRADIENT_ACCUMULATE_EVERY = 4\n",
        "LEARNING_RATE = 1e-4\n",
        "VALIDATE_EVERY  = 100\n",
        "GENERATE_EVERY  = 500\n",
        "GENERATE_LENGTH = 2048\n",
        "SEQ_LEN = 2048\n",
        "\n",
        "# helpers\n",
        "\n",
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "def decode_token(token):\n",
        "    return str(chr(max(32, token)))\n",
        "\n",
        "def decode_tokens(tokens):\n",
        "    return ''.join(list(map(decode_token, tokens)))\n",
        "\n",
        "# instantiate GPT-like decoder model\n",
        "\n",
        "model = TransformerWrapper(\n",
        "    num_tokens = 256,\n",
        "    max_seq_len = SEQ_LEN,\n",
        "    attn_layers = Decoder(dim = 512, depth = 6, heads = 8)\n",
        ")\n",
        "\n",
        "model = AutoregressiveWrapper(model)\n",
        "model.cuda()\n",
        "\n",
        "# prepare enwik8 data\n",
        "\n",
        "with open('/content/Optimus-VIRTUOSO-Music-Dataset.txt', 'r') as file:\n",
        "  z = file.read()\n",
        "Z = z.encode('utf8')\n",
        "Y = list(Z)\n",
        "\n",
        "\n",
        "\n",
        "trX, vaX = np.split(Y, [int(1000000)])\n",
        "data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
        "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))\n",
        "\n",
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOGIoP5SOyNS",
        "cellView": "form"
      },
      "source": [
        "#@title Train the model\n",
        "# training\n",
        "\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
        "        loss = model(next(train_loader))\n",
        "        loss.backward()\n",
        "\n",
        "    print(f'training loss: {loss.item()}')\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    if i % VALIDATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss = model(next(val_loader))\n",
        "            print(f'validation loss: {loss.item()}')\n",
        "\n",
        "    if i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        inp = random.choice(val_dataset)[:-1]\n",
        "        prime = decode_tokens(inp)\n",
        "        print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "        sample = model.generate(inp, GENERATE_LENGTH)\n",
        "        output_str = decode_tokens(sample)\n",
        "        print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd0O1XfqxuN6",
        "cellView": "form"
      },
      "source": [
        "#@title Save the model\n",
        "torch.save(model, '/content/model.pth')\n",
        "torch.save(model.state_dict, '/content/model_sd.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exl6DHvwGGT2",
        "cellView": "form"
      },
      "source": [
        "#@title Load a model\n",
        "model = torch.load('/content/model.pth')\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq3G03EA1GGg",
        "cellView": "form"
      },
      "source": [
        "#@title Generate from the model\n",
        "\n",
        "inp = random.choice(val_dataset)[:-1]\n",
        "prime = decode_tokens(inp)\n",
        "print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "sample = model.generate(inp[:16], GENERATE_LENGTH, temperature=0.8) #GENERATE_LENGTH)\n",
        "output_str = decode_tokens(sample)\n",
        "print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Da12PiKbJj"
      },
      "source": [
        "S = TMIDI.Tegridy_Optimus_TXT_to_Notes_Converter('SONG=TEST' + output_str, line_by_line_dataset = False, has_MIDI_channels=False, has_velocities=True, dataset_MIDI_events_time_denominator=10, char_encoding_offset=33, simulate_velocity=False)\n",
        "stats = TMIDI.Tegridy_SONG_to_MIDI_Converter(SONG=S[0], output_file_name='/content/test')\n",
        "print(stats)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}