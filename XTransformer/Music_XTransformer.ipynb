{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Music_XTransformer.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8p4NIXjC6vs"
      },
      "source": [
        "# Music XTransformer (PyTorch/GPU) (Ver 1.0)\n",
        "\n",
        "***\n",
        "\n",
        "Credit for the PyTorch XTransformer implementation goes out to @lucidrains of GitHub: \n",
        "\n",
        "https://github.com/lucidrains/x-transformers\n",
        "\n",
        "***\n",
        "\n",
        "This is a work in progress so please check back for updates.\n",
        "\n",
        "***\n",
        "\n",
        "Project Los Angeles\n",
        "\n",
        "Tegridy Code 2021\n",
        "\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUQ2ytG6OSfn"
      },
      "source": [
        "# Setup the environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2IUeSaiveLL",
        "cellView": "form"
      },
      "source": [
        "#@title Install dependencies\n",
        "!git clone https://github.com/asigalov61/tegridy-tools\n",
        "!pip install x-transformers\n",
        "!pip install numpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTR81Sflrb7_",
        "cellView": "form"
      },
      "source": [
        "#@title Import all needed modules\n",
        "\n",
        "print('Loading needed modules. Please wait...')\n",
        "import os\n",
        "\n",
        "if not os.path.exists('/content/Dataset'):\n",
        "    os.makedirs('/content/Dataset')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "os.chdir('/content/tegridy-tools/tegridy-tools')\n",
        "import TMIDI\n",
        "os.chdir('/content/')\n",
        "\n",
        "from x_transformers import TransformerWrapper, Decoder\n",
        "from x_transformers.autoregressive_wrapper import AutoregressiveWrapper\n",
        "\n",
        "import random\n",
        "import tqdm\n",
        "import gzip\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6yox68cOMAG"
      },
      "source": [
        "# Prep the MIDIs and TXT/INT datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCyeRdx8Jmxc",
        "cellView": "form"
      },
      "source": [
        "#@title Download special Tegridy Piano MIDI dataset\n",
        "\n",
        "#@markdown Works best stand-alone/as-is for the optimal results\n",
        "%cd /content/Dataset/\n",
        "\n",
        "!wget 'https://github.com/asigalov61/Tegridy-MIDI-Dataset/raw/master/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "!unzip -j '/content/Dataset/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "!rm '/content/Dataset/Tegridy-Piano-CC-BY-NC-SA.zip'\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "fIfAhq8TC9rh"
      },
      "source": [
        "#@title Download special Synthetic Tegridy Piano MIDI dataset\n",
        "\n",
        "#@markdown Works best stand-alone/as-is for the optimal results\n",
        "%cd /content/Dataset/\n",
        "\n",
        "!wget 'https://github.com/asigalov61/Tegridy-MIDI-Dataset/raw/master/Synthetic-Tegridy-Piano-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "!unzip '/content/Dataset/Synthetic-Tegridy-Piano-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "!rm '/content/Dataset/Synthetic-Tegridy-Piano-MIDI-Dataset-CC-BY-NC-SA.zip'\n",
        "\n",
        "%cd /content/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZX8SYA1Jrig",
        "cellView": "form"
      },
      "source": [
        "#@title Process MIDIs to special MIDI dataset with Tegridy MIDI Processor\n",
        "#@markdown NOTES:\n",
        "\n",
        "#@markdown 1) Dataset MIDI file names are used as song names. Feel free to change it to anything you like.\n",
        "\n",
        "#@markdown 2) Best results are achieved with the single-track, single-channel, single-instrument MIDI 0 files with plain English names (avoid special or sys/foreign chars)\n",
        "\n",
        "#@markdown 3) MIDI Channel = -1 means all MIDI channels except drums. MIDI Channel = 16 means all channels will be processed. Otherwise, only single indicated MIDI channel will be processed.\n",
        "\n",
        "file_name_to_output_dataset_to = \"/content/Music-XTransformer_TXT_Dataset\" #@param {type:\"string\"}\n",
        "desired_MIDI_channel_to_process = 16 #@param {type:\"slider\", min:-1, max:16, step:1}\n",
        "encode_velocities = True #@param {type:\"boolean\"}\n",
        "encode_MIDI_channels = False #@param {type:\"boolean\"}\n",
        "add_transposed_dataset_by_this_many_pitches = 0 #@param {type:\"slider\", min:-12, max:12, step:1}\n",
        "chordify_input_MIDIs = False #@param {type:\"boolean\"}\n",
        "time_denominator = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "chars_encoding_offset = 33 #@param {type:\"number\"}\n",
        "\n",
        "\n",
        "print('Starting up...')\n",
        "###########\n",
        "\n",
        "average_note_pitch = 0\n",
        "min_note = 127\n",
        "max_note = 0\n",
        "\n",
        "files_count = 0\n",
        "\n",
        "ev = 0\n",
        "\n",
        "chords_list_f = []\n",
        "melody_list_f = []\n",
        "\n",
        "chords_list = []\n",
        "chords_count = 0\n",
        "\n",
        "melody_chords = []\n",
        "melody_count = 0\n",
        "\n",
        "TXT_String = 'DATASET=Music-XTransformer-Dataset' + chr(10)\n",
        "\n",
        "TXT = ''\n",
        "melody = []\n",
        "chords = []\n",
        "\n",
        "###########\n",
        "\n",
        "print('Loading MIDI files...')\n",
        "print('This may take a while on a large dataset in particular.')\n",
        "\n",
        "dataset_addr = \"/content/Dataset/\"\n",
        "os.chdir(dataset_addr)\n",
        "filez = os.listdir(dataset_addr)\n",
        "\n",
        "print('Processing MIDI files. Please wait...')\n",
        "for f in tqdm.auto.tqdm(filez):\n",
        "  try:\n",
        "    fn = os.path.basename(f)\n",
        "    fn1 = fn.split('.')[0]\n",
        "    #notes = song_notes_list[song_notes_list.index(fn1)+1]\n",
        "\n",
        "\n",
        "    files_count += 1\n",
        "    TXT, melody, chords = TMIDI.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=encode_MIDI_channels, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_channel=desired_MIDI_channel_to_process, MIDI_patch=range(0, 127))\n",
        "    TXT_String += TXT\n",
        "    melody_list_f += melody\n",
        "    chords_list_f += chords\n",
        "\n",
        "    if add_transposed_dataset_by_this_many_pitches != 0:\n",
        "\n",
        "      TXT, melody, chords = TMIDI.Optimus_MIDI_TXT_Processor(f, chordify_TXT=chordify_input_MIDIs, output_MIDI_channels=encode_MIDI_channels, char_offset=chars_encoding_offset, dataset_MIDI_events_time_denominator=time_denominator, output_velocity=encode_velocities, MIDI_channel=desired_MIDI_channel_to_process, transpose_by=add_transposed_dataset_by_this_many_pitches, MIDI_patch=range(0, 127))\n",
        "      TXT_String += TXT\n",
        "      melody_list_f += melody\n",
        "      chords_list_f += chords   \n",
        "    #TXT_String += 'INTRO=' + notes + '\\n'\n",
        "    \n",
        "  \n",
        "  except:\n",
        "    print('Bad MIDI:', f)\n",
        "    continue\n",
        "\n",
        "print('Task complete :)')\n",
        "print('==================================================')\n",
        "print('Number of processed dataset MIDI files:', files_count)\n",
        "print('Number of MIDI chords recorded:', len(chords_list_f))\n",
        "print('First chord event:', chords_list_f[0], 'Last chord event:', chords_list_f[-1]) \n",
        "print('Number of recorded melody events:', len(melody_list_f))\n",
        "print('First melody event:', melody_list_f[0], 'Last Melody event:', melody_list_f[-1])\n",
        "print('Total number of MIDI events recorded:', len(chords_list_f) + len(melody_list_f))\n",
        "\n",
        "# Writing dataset to TXT file\n",
        "with open(file_name_to_output_dataset_to + '.txt', 'wb') as f:\n",
        "  f.write(TXT_String.encode('utf-8', 'replace'))\n",
        "  f.close\n",
        "\n",
        "# Dataset\n",
        "MusicDataset = [chords_list_f, melody_list_f]\n",
        "\n",
        "# Writing dataset to pickle file\n",
        "TMIDI.Tegridy_Pickle_File_Writer(MusicDataset, file_name_to_output_dataset_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-f6AEIdLLud",
        "cellView": "form"
      },
      "source": [
        "#@title Process the TXT MIDI dataset to TXT INT dataset\n",
        "full_path_to_TXT_dataset = \"/content/Music-XTransformer_TXT_Dataset.txt\" #@param {type:\"string\"}\n",
        "\n",
        "print('Processing...')\n",
        "with open(full_path_to_TXT_dataset) as file:\n",
        "  z = file.read()\n",
        "  file.close()\n",
        "  Y = list(z)\n",
        "\n",
        "string = '\\n'.join([str(ord(item)) for item in Y if ord(item) < 256])\n",
        "\n",
        "with open('/content/Music-XTransformer_INT_Dataset.txt', 'w') as file:\n",
        "  file.write(string)\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A3CW9qrLMU8",
        "cellView": "form"
      },
      "source": [
        "#@title Load INT dataset into memory and setup the dataset\n",
        "full_path_to_INT_dataset = \"/content/Music-XTransformer_INT_Dataset.txt\" #@param {type:\"string\"}\n",
        "dataset_split_ratio = 0.9 #@param {type:\"slider\", min:0.1, max:0.9, step:0.1}\n",
        "\n",
        "print('Processing...')\n",
        "with open(full_path_to_INT_dataset) as file:\n",
        "    X = file.read()\n",
        "    H = []\n",
        "    for x in X.split('\\n'):\n",
        "      H.append(int(x))\n",
        "\n",
        "trX, vaX = np.split(H, [int(len(H) * dataset_split_ratio)])\n",
        "data_train, data_val = torch.from_numpy(trX), torch.from_numpy(vaX)\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fURKAJrOCSb"
      },
      "source": [
        "# Setup and Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7czqOs-OeVO",
        "cellView": "form"
      },
      "source": [
        "#@title Setup and intialize the model\n",
        "# constants\n",
        "\n",
        "NUM_BATCHES = int(1e5)\n",
        "BATCH_SIZE = 6\n",
        "GRADIENT_ACCUMULATE_EVERY = 4\n",
        "LEARNING_RATE = 1e-4\n",
        "VALIDATE_EVERY  = 100\n",
        "GENERATE_EVERY  = 500\n",
        "GENERATE_LENGTH = 2048\n",
        "SEQ_LEN = 2048\n",
        "\n",
        "# helpers\n",
        "\n",
        "def cycle(loader):\n",
        "    while True:\n",
        "        for data in loader:\n",
        "            yield data\n",
        "\n",
        "def decode_token(token):\n",
        "    return str(chr(max(32, token)))\n",
        "\n",
        "def decode_tokens(tokens):\n",
        "    return ''.join(list(map(decode_token, tokens)))\n",
        "\n",
        "# instantiate GPT-like decoder model\n",
        "\n",
        "model = TransformerWrapper(\n",
        "    num_tokens = 256,\n",
        "    max_seq_len = SEQ_LEN,\n",
        "    attn_layers = Decoder(dim = 512, depth = 6, heads = 8)\n",
        ")\n",
        "\n",
        "model = AutoregressiveWrapper(model)\n",
        "model.cuda()\n",
        "\n",
        "'''========================================='''\n",
        "\n",
        "class TextSamplerDataset(Dataset):\n",
        "    def __init__(self, data, seq_len):\n",
        "        super().__init__()\n",
        "        self.data = data\n",
        "        self.seq_len = seq_len\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        rand_start = torch.randint(0, self.data.size(0) - self.seq_len - 1, (1,))\n",
        "        full_seq = self.data[rand_start: rand_start + self.seq_len + 1].long()\n",
        "        return full_seq.cuda()\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.size(0) // self.seq_len\n",
        "\n",
        "train_dataset = TextSamplerDataset(data_train, SEQ_LEN)\n",
        "val_dataset   = TextSamplerDataset(data_val, SEQ_LEN)\n",
        "train_loader  = cycle(DataLoader(train_dataset, batch_size = BATCH_SIZE))\n",
        "val_loader    = cycle(DataLoader(val_dataset, batch_size = BATCH_SIZE))\n",
        "\n",
        "# optimizer\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOGIoP5SOyNS",
        "cellView": "form"
      },
      "source": [
        "#@title Train the model\n",
        "# training\n",
        "\n",
        "for i in tqdm.tqdm(range(NUM_BATCHES), mininterval=10., desc='training'):\n",
        "    model.train()\n",
        "\n",
        "    for __ in range(GRADIENT_ACCUMULATE_EVERY):\n",
        "        loss = model(next(train_loader))\n",
        "        loss.backward()\n",
        "\n",
        "    print(f'training loss: {loss.item()}')\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
        "    optim.step()\n",
        "    optim.zero_grad()\n",
        "\n",
        "    if i % VALIDATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            loss = model(next(val_loader))\n",
        "            print(f'validation loss: {loss.item()}')\n",
        "\n",
        "    if i % GENERATE_EVERY == 0:\n",
        "        model.eval()\n",
        "        inp = random.choice(val_dataset)[:-1]\n",
        "        prime = decode_tokens(inp)\n",
        "        print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        "\n",
        "        sample = model.generate(inp, GENERATE_LENGTH)\n",
        "        output_str = decode_tokens(sample)\n",
        "        print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RmIeZiNN7Ob"
      },
      "source": [
        "# Save and Load/Reload the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd0O1XfqxuN6",
        "cellView": "form"
      },
      "source": [
        "#@title Save the model\n",
        "torch.save(model.state_dict(), '/content/Music-XTransformer-Model.pth')\n",
        "\n",
        "checkpoint = {'state_dict': model.state_dict(),'optimizer' :optim.state_dict()}\n",
        "torch.save(checkpoint, '/content/Music-XTransformer-Model_sd_opt.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exl6DHvwGGT2",
        "cellView": "form"
      },
      "source": [
        "#@title Load/Reload the model\n",
        "model = torch.load('/content/Music-XTransformer-Model.pth')\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjRBNATJN3Pj"
      },
      "source": [
        "# Generate from the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq3G03EA1GGg",
        "cellView": "form"
      },
      "source": [
        "#@title Generate Music\n",
        "number_of_tokens_to_generate = 3976 #@param {type:\"slider\", min:8, max:4096, step:128}\n",
        "model_temperature = 1 #@param {type:\"slider\", min:0.1, max:2, step:0.1}\n",
        "\n",
        "inp = random.choice(val_dataset)[:-1]\n",
        "prime = decode_tokens(inp)\n",
        "print(f'%s \\n\\n %s', (prime, '*' * 100))\n",
        " \n",
        "sample = model.generate(start_tokens=inp[:16], seq_len=number_of_tokens_to_generate, temperature=model_temperature) #GENERATE_LENGTH)\n",
        "output_str = decode_tokens(sample)\n",
        "print(output_str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Da12PiKbJj",
        "cellView": "form"
      },
      "source": [
        "#@title Convert generated output to MIDI\n",
        "time_denominator = 10 #@param {type:\"slider\", min:1, max:20, step:1}\n",
        "encoding_has_velocities = True #@param {type:\"boolean\"}\n",
        "simulate_velocity = False #@param {type:\"boolean\"}\n",
        "char_encoding_offset = 33 #@param {type:\"number\"}\n",
        "include_primer_in_output = True #@param {type:\"boolean\"}\n",
        "save_only_first_composition = True #@param {type:\"boolean\"}\n",
        "\n",
        "if include_primer_in_output:\n",
        "  SONG = TMIDI.Tegridy_Optimus_TXT_to_Notes_Converter('SONG=SONG\\n' + prime + '\\n' + output_str, line_by_line_dataset = False, has_MIDI_channels=False, has_velocities=encoding_has_velocities, dataset_MIDI_events_time_denominator=time_denominator, char_encoding_offset=char_encoding_offset, simulate_velocity=simulate_velocity)\n",
        "else:\n",
        "  SONG = TMIDI.Tegridy_Optimus_TXT_to_Notes_Converter('SONG=SONG\\n' + output_str, line_by_line_dataset = False, has_MIDI_channels=False, has_velocities=encoding_has_velocities, dataset_MIDI_events_time_denominator=time_denominator, char_encoding_offset=char_encoding_offset, simulate_velocity=simulate_velocity, save_only_first_composition=save_only_first_composition)\n",
        "\n",
        "stats = TMIDI.Tegridy_SONG_to_MIDI_Converter(SONG[0], output_file_name='/content/Music-XTransformer_MIDI', output_signature='Music XTransformer')\n",
        "print(stats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW_ka1kjNy2G"
      },
      "source": [
        "# Congrats! You did it :)"
      ]
    }
  ]
}